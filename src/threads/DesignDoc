	+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Hao Ho hhho42@tntech.edu
Izaiah Townsend Witownsend42@tntech.edu
Daniel Attih 	 dattih42@tntech.edu
Avery Richardson arichards44@tntech.edu

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

Sleep_thread structure holds thread regerence and wake-up time. It also used to manage sleeping threads in timer_sleep().
Sleep_list is a global list of sleep threads that is order by wake-up time for efficient handling in the timer interrupt.

---- ALGORITHMS ----

When timer_sleep() is called, the wake-up time of the thread is calculated and added to sleep_list. The timer interrupt handler wakes threads when their time expires. The timer interrupt handler only checks the front of sleep_list to minimize overhead, ensuring constant-time complexity when handling expired threads.

---- SYNCHRONIZATION ----

A lock protects access to sleep_list to prevent race conditions when multiple threads call timer_sleep() concurrently. Disabling interrupts briefly while modifying sleep_list ensures no race conditions occur between timer_sleep() and the timer interrupt handler.

---- RATIONALE ----

This design minimizes interrupt handler work by only checking the next wake-up time. It reduces contention with a single lock and avoids busy-waiting. Alternative designs like per-thread timers added complexity without improving efficiency.
The Design mininmizes the interrupt handler work by only checking the next time a wake-up time happens. It reduces contention with single lock and it also avoids busy-waiting. Different designs, such as per-thread timer, adds complexity without improving efficiency.
			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

The stucture thread can add donated_priority to track the donations and use lock_waiting to track the lock the thread is waiting on. While the structure lock adds max_priority to track the highest priority among waiting threads for donation handling

Diagram:
Thread A (priority 10) holds Lock X
Thread B (priority 20) waits for Lock X
Thread C (priority 30) waits for Lock Y, held by Thread B

Thread C â†’ Lock Y â†’ Thread B â†’ Lock X â†’ Thread A

---- ALGORITHMS ----

Locks, semaphores, and condition variables use priority queues (sorted lists) to track waiting threads, ensuring the highest-priority thread is always first.

When lock_acquire() is called:
  - If held, the thread donates its priority to the lock holder.
  - If waiting for another lock, the donation propagates up the chain (nested donation)

When lock_release() is called:
  - The releasing thread removes the donation from its priority.
  - The highest-priority waiting thread acquires the lock, and the thread's original priority is restored.

---- SYNCHRONIZATION ----

In thread_set_priority(), a race could occur if priority changes happen while a donation is happening. Because of this issue, a lock is used to protet priority changes that would cause deadlocks, so we would need to briefly disable interrupts when updating priorities to prevent races.

---- RATIONALE ----

This design ensures minimal complexity while handling nested donations efficiently. Different designs, like per-lock priority queues, adds complexity without improving fairness or efficiency. 
Using a global priority queue avoided unnecessary data structures and kept the code simple.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

struct thread:
  - recent_cpu: Tracks CPU time received by the thread, used for advanced scheduling.
  - nice: Represents thread "niceness," influencing priority for fair CPU allocation.
load_avg: Global variable representing system load average, used in priority and recent CPU calculations.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0   63  61  59   A
 4      4   0   0   62  61  59   A
 8      8   0   0   61  61  59   A
12      12  0   0   60  61  59   B
16      12  4   0   60  60  59   B
20      12  8   0   60  59  59   C
24      12  8   4   60  59  59   C
28      12  8   8   60  50  57   A
32      16  8   8   59  59  57   A
36      20  8   8   58  59  57   B

Yes, some ambiguities affect the table values:
  - Priority Updates: Itâ€™s unclear if priorities update every 4 ticks or only when threads yield. I assumed every 4 ticks.
  - Ties in Priority: When threads have equal priority, the spec doesnâ€™t say how to pick one. I chose the longest-waiting thread.
  - Load Average: The spec is vague on when load_avg affects priority. I applied updates right after recalculating load_avg.
  - recent_cpu: Itâ€™s unclear if recent_cpu increases only for the running thread or all threads. I assumed only the running thread.


Keep interrupt context work minimal by only updating essential values like recent_cpu and checking if a thread needs to wake up. Most heavy tasks, like recalculating priorities and selecting the next thread, happen outside the interrupt context. This reduces the time spent with interrupts disabled, lowering the risk of missed interrupts and improving responsiveness.

---- RATIONALE ----

Advantages:
  - Efficiency: Minimizing work in the interrupt handler reduces scheduling overhead and keeps the system responsive.
  - Fairness: Using recent_cpu and nice values balances CPU distribution across threads.
  - Simplicity: The design is straightforward, making priority calculations and thread management easy to understand and maintain.

Disadvantages:
  - Priority Inversion: Priority donation isnâ€™t perfect in nested cases, potentially causing delays in priority restoration.
  - Granularity: Updating priorities every 4 ticks may cause slight delays in reflecting priority changes, especially in short-lived threads.
  - Complexity in Nested Donation: Handling nested priority donations can get tricky, especially when multiple locks are involved.

Improvements:
  - Fine-Grained Priority Updates: Update priorities more frequently or dynamically based on system load.
  - Better Load Balancing: Implement load-aware scheduling by considering system load when selecting the next thread.
  - Optimize Nested Donation: Simplify the donation chain management to avoid redundant recalculations.

We're not sure what to implment it yet as we have not done it, we've been doing research on the project before starting it. 

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

No, I think that this assignment is just the right amount of hard and easy while taking the right amount of time as well.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Yes, it's interesting to learn about this. It could also be used as reference for the project.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

No really, I feel that the questions were straight forward and simple to understand. These questions can easily be answered by finding it.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

Since this assignment isn't too hard, TAs can just help if someone needs it.

>> Any other comments?

Make it due next Thursday as most students don't want to work over Spring break or the week prior to it
